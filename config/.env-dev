general = efs/models/Llama-3.1.gguf
classifier_tokenizer = efs/classifier/tokenizer.pickle
classifier_model = efs/classifier/KM_Classifier.onnx
LLAMA_CPP_HOME = /opt/cx_intelligence/aiaas/compiled_llama_cpp
LLAMA_SOURCE_FOLDER = efs/frameworks/llama.cpp
HOST = 0.0.0.0
UVICORN_PORT = 8000
LLAMA_PORT = 8001
CHROMA_PORT = 8099
CHROMA_DATA_PATH = efs/chroma
NUMBER_OF_SERVERS = 1
BATCH_SIZE = 8196
UBATCH_SIZE = 1024
GPU_LAYERS = 99
SPLIT_SYMBOL = :::
CHATML_TEMPLATE = chatml
LLAMA3_TEMPLATE = llama3
MAX_CALLS = 35
API_TOKENS = fja0w3fj039jwiej092j0j-9ajw-3j-a9j-ea,0293fj09q3jw[ajwf90j3af[ja0j4f0a49jj9f-aj9f,20493jrt09q3jgt09aejgf0aj9t09j4-t921jtr1=t=9eut=,0243t9q093tjg0-93gj-39j-r0faipjfoan948fj-fgj-,f940jqa3-gjf-q2fja0-jt034jt-90qaj32-tf,jf0293jf-09qja2f3-9q2jf-0qj-02j3-q3-09fj-9qj--034tkj-0,029fj093j2f0-9j2-9q2-9fj-q2f0-jfjaonnbiunmq09jrt304
CUDA_VISIBLE_DEVICES = 0
USE_FLASH_ATTENTION=1
MAIN_GPU_INDEX = 0