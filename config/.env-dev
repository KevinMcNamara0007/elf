MODEL_DIR = /opt/models
GENERAL_MODEL = Llama-3.1.gguf
VISION_MODEL_DIR = microsoft/Phi-3-vision-128k-instruct-onnx-cpu/cpu-int4-rtn-block-32-acc-level-4
CLASSIFIER_TOKENIZER = efs/classifier/tokenizer.pickle
CLASSIFIER_MODEL = efs/classifier/KM_Classifier.onnx
CHROMA_DATA_PATH = efs/chroma
LLAMA_CPP_HOME = /opt/cx_intelligence/aiaas/compiled_llama_cpp
LLAMA_SOURCE_FOLDER = efs/frameworks/llama.cpp
CUDA_VISIBLE_DEVICES = 0
USE_FLASH_ATTENTION=1
MAIN_GPU_INDEX = 0
HOST = 127.0.0.1
UVICORN_PORT = 8000
CONTEXT_WINDOW = 131072
INPUT_WINDOW = 16384
NUMBER_OF_SERVERS = 1
BATCH_SIZE = 8196
UBATCH_SIZE = 1024
GPU_LAYERS = 99
SPLIT_SYMBOL = :::
CHATML_TEMPLATE = chatml
LLAMA3_TEMPLATE = llama3
API_TOKENS = 0293fj09q3jw[ajwf90j3af[ja0j4f0a49jj9f-aj9f,20493jrt09q3jgt09aejgf0aj9t09j4-t921jtr1=t=9eut=,0243t9q093tjg0-93gj-39j-r0faipjfoan948fj-fgj-,f940jqa3-gjf-q2fja0-jt034jt-90qaj32-tf,jf0293jf-09qja2f3-9q2jf-0qj-02j3-q3-09fj-9qj--034tkj-0,029fj093j2f0-9j2-9q2-9fj-q2f0-jfjaonnbiunmq09jrt304